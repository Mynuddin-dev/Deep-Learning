<h1 align="center"> Deep-Learning </h1>


- [Deep Learning basic theory | Krish Naik](https://www.youtube.com/watch?v=YFNKnUhm_-s&list=PLZoTAELRMXVPGU70ZGsckrMdr0FteeRUi&index=1)
- [Andrej Karpathy Complete deep learning course***](https://www.youtube.com/watch?v=i94OvYb6noo&list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC&index=4)
- [Neural Networks | IBM](https://www.ibm.com/cloud/learn/neural-networks)
- [Neural networks | 3Blue1Brown](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
- Gradient Descent
    - [Gradient Descent | IBM](https://www.ibm.com/cloud/learn/gradient-descent)
    - [The Challenge of Vanishing/Exploding Gradients in Deep Neural Networks](https://www.analyticsvidhya.com/blog/2021/06/the-challenge-of-vanishing-exploding-gradients-in-deep-neural-networks/)
    - [Variants of Gradient Descent Algorithm](https://www.analyticsvidhya.com/blog/2021/03/variants-of-gradient-descent-algorithm/)
    - [Batch, Mini Batch & Stochastic Gradient Descent](https://towardsdatascience.com/batch-mini-batch-stochastic-gradient-descent-7a62ecba642a)
    - [Deep Learning-All Optimizers](https://www.youtube.com/watch?v=TudQZtgpoHk&list=PLZoTAELRMXVPGU70ZGsckrMdr0FteeRUi&index=22)
- Activation Function
    - [Activation Functions in Neural Networks [12 Types & Use Cases]](https://www.v7labs.com/blog/neural-networks-activation-functions#h1)
    - [How to Choose an Activation Function for Deep Learning](https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/)
    - [Fundamentals of Deep Learning â€“ Activation Functions and When to Use Them?](https://www.analyticsvidhya.com/blog/2020/01/fundamentals-deep-learning-activation-functions-when-to-use-them/) 
    - [Keras layer activation function](https://keras.io/api/layers/activations/)
    - [tf-keras activation function](https://www.tensorflow.org/api_docs/python/tf/keras/activations)
- Dropout Layer
    - [Dropout Layer - The unconventional regularization technique | 2nd paragraph**](https://deepnotes.io/dropout)
    - [Are these dropped out neurons also zeros (turned off) during back-prop ?](https://stats.stackexchange.com/questions/219236/dropout-forward-prop-vs-back-prop-in-machine-learning-neural-network)
    - [neuralthreads | medium](https://medium.com/@neuralthreads)



